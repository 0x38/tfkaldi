<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.5">
  <compounddef id="nnetgraph_8py" kind="file">
    <compoundname>nnetgraph.py</compoundname>
    <innerclass refid="classnnetgraph_1_1NnetGraph" prot="public">nnetgraph::NnetGraph</innerclass>
    <innerclass refid="classnnetgraph_1_1DNN" prot="public">nnetgraph::DNN</innerclass>
    <innerclass refid="classnnetgraph_1_1NnetDecoder" prot="public">nnetgraph::NnetDecoder</innerclass>
    <innerclass refid="classnnetgraph_1_1NnetTrainer" prot="public">nnetgraph::NnetTrainer</innerclass>
    <innerclass refid="classnnetgraph_1_1CallableTensor" prot="public">nnetgraph::CallableTensor</innerclass>
    <innernamespace refid="namespacennetgraph">nnetgraph</innernamespace>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <programlisting>
<codeline lineno="1"><highlight class="keyword">import</highlight><highlight class="normal"><sp/>tensorflow<sp/></highlight><highlight class="keyword">as</highlight><highlight class="normal"><sp/>tf</highlight></codeline>
<codeline lineno="2"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>numpy<sp/></highlight><highlight class="keyword">as</highlight><highlight class="normal"><sp/>np</highlight></codeline>
<codeline lineno="3"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>abc<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>ABCMeta,<sp/>abstractmethod,<sp/>abstractproperty</highlight></codeline>
<codeline lineno="4"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>itertools</highlight></codeline>
<codeline lineno="5"><highlight class="normal"></highlight></codeline>
<codeline lineno="6"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>nnetlayer</highlight></codeline>
<codeline lineno="7"><highlight class="normal"></highlight></codeline>
<codeline lineno="8"><highlight class="normal"></highlight><highlight class="comment">##This<sp/>an<sp/>abstrace<sp/>class<sp/>defining<sp/>a<sp/>neural<sp/>net</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="9" refid="classnnetgraph_1_1NnetGraph" refkind="compound"><highlight class="normal"></highlight><highlight class="keyword">class<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetGraph" kindref="compound">NnetGraph</ref>(object):</highlight></codeline>
<codeline lineno="10"><highlight class="normal"><sp/><sp/><sp/><sp/>__metaclass__<sp/>=<sp/>ABCMeta</highlight></codeline>
<codeline lineno="11"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="12"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##NnetGraph<sp/>constructor</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="13"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="14"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>name<sp/>name<sp/>of<sp/>the<sp/>neural<sp/>network</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="15"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>args<sp/>arguments<sp/>that<sp/>will<sp/>be<sp/>used<sp/>as<sp/>properties<sp/>of<sp/>the<sp/>neural<sp/>net</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="16"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>kwargs<sp/>named<sp/>arguments<sp/>that<sp/>will<sp/>be<sp/>used<sp/>as<sp/>properties<sp/>of<sp/>the<sp/>neural<sp/>net</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="17"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetGraph_1a577e7223d32195828eecacca5e7fe22f" kindref="member">__init__</ref>(self,<sp/>name,<sp/>*args,<sp/>**kwargs):</highlight></codeline>
<codeline lineno="18"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="19"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetGraph_1a64645c360c6ebfc12489ce179f470053" kindref="member">name</ref><sp/>=<sp/>name</highlight></codeline>
<codeline lineno="20"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="21"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>len(args)<sp/>+<sp/>len(kwargs)<sp/>!=<sp/>len(self.<ref refid="classnnetgraph_1_1NnetGraph_1ab6ae9e134b34173649c3a18f3463e03f" kindref="member">fieldnames</ref>):</highlight></codeline>
<codeline lineno="22"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>TypeError(</highlight><highlight class="stringliteral">&apos;%s()<sp/>expects<sp/>%d<sp/>arguments<sp/>(%d<sp/>given)&apos;</highlight><highlight class="normal"><sp/>%(type(self).__name__,<sp/>len(self.<ref refid="classnnetgraph_1_1NnetGraph_1ab6ae9e134b34173649c3a18f3463e03f" kindref="member">fieldnames</ref>),<sp/>len(args)<sp/>+<sp/>len(kwargs)))</highlight></codeline>
<codeline lineno="23"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="24"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>a<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>range(len(args)):</highlight></codeline>
<codeline lineno="25"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>exec(</highlight><highlight class="stringliteral">&apos;self.%s<sp/>=<sp/>args[a]&apos;</highlight><highlight class="normal"><sp/>%<sp/>self.<ref refid="classnnetgraph_1_1NnetGraph_1ab6ae9e134b34173649c3a18f3463e03f" kindref="member">fieldnames</ref>[a])</highlight></codeline>
<codeline lineno="26"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="27"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>a<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>kwargs:</highlight></codeline>
<codeline lineno="28"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>a<sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>self.<ref refid="classnnetgraph_1_1NnetGraph_1ab6ae9e134b34173649c3a18f3463e03f" kindref="member">fieldnames</ref>:</highlight></codeline>
<codeline lineno="29"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>TypeError(</highlight><highlight class="stringliteral">&apos;%s<sp/>is<sp/>an<sp/>invalid<sp/>keyword<sp/>argument<sp/>for<sp/>%s()&apos;</highlight><highlight class="normal"><sp/>%<sp/>(a,<sp/>type(self).__name__))</highlight></codeline>
<codeline lineno="30"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="31"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>exec(</highlight><highlight class="stringliteral">&apos;self.%s<sp/>=<sp/>kwargs[a]&apos;</highlight><highlight class="normal"><sp/>%<sp/>(a))</highlight></codeline>
<codeline lineno="32"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="33"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##Extends<sp/>the<sp/>graph<sp/>with<sp/>the<sp/>neural<sp/>net<sp/>graph,<sp/>this<sp/>method<sp/>should<sp/>define<sp/>the<sp/>attributes:<sp/>inputs,<sp/>outputs,<sp/>logits<sp/>and<sp/>saver.<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="34"><highlight class="normal"><sp/><sp/><sp/><sp/>@abstractmethod</highlight></codeline>
<codeline lineno="35"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetGraph_1a25f6ec53d746ada07a4064db60c9f57c" kindref="member">extendGraph</ref>(self):</highlight></codeline>
<codeline lineno="36"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="37"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="38"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##A<sp/>list<sp/>of<sp/>strings<sp/>containing<sp/>the<sp/>fielnames<sp/>of<sp/>the<sp/>__init__<sp/>function</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="39"><highlight class="normal"><sp/><sp/><sp/><sp/>@abstractproperty</highlight></codeline>
<codeline lineno="40"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetGraph_1ab6ae9e134b34173649c3a18f3463e03f" kindref="member">fieldnames</ref>(self):</highlight></codeline>
<codeline lineno="41"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="42"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="43"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##Inputs<sp/>placeholder</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="44"><highlight class="normal"><sp/><sp/><sp/><sp/>@property</highlight></codeline>
<codeline lineno="45"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetGraph_1a5fb27655f740d4b9c2e99cf3bcb78547" kindref="member">inputs</ref>(self):</highlight></codeline>
<codeline lineno="46"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>self.<ref refid="classnnetgraph_1_1NnetGraph_1a4954a87025ee4bbc4963773a292fb49a" kindref="member">_inputs</ref></highlight></codeline>
<codeline lineno="47"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="48"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##Outputs<sp/>of<sp/>the<sp/>graph</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="49"><highlight class="normal"><sp/><sp/><sp/><sp/>@property</highlight></codeline>
<codeline lineno="50"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetGraph_1aeba1946cfab246f3475bd251c083dbf6" kindref="member">outputs</ref>(self):</highlight></codeline>
<codeline lineno="51"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>self.<ref refid="classnnetgraph_1_1NnetGraph_1a080dd4e4e378af6a2667151807f20d64" kindref="member">_outputs</ref></highlight></codeline>
<codeline lineno="52"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="53"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##Logits<sp/>used<sp/>for<sp/>training</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="54"><highlight class="normal"><sp/><sp/><sp/><sp/>@property</highlight></codeline>
<codeline lineno="55"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetGraph_1a7e52824ec329ad67a1f3c46e2167e784" kindref="member">trainlogits</ref>(self):</highlight></codeline>
<codeline lineno="56"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>self.<ref refid="classnnetgraph_1_1NnetGraph_1a1b1357c29560703c90091644b859aff7" kindref="member">_trainlogits</ref></highlight></codeline>
<codeline lineno="57"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="58"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##Logits<sp/>used<sp/>for<sp/>evaluating<sp/>(can<sp/>be<sp/>the<sp/>same<sp/>as<sp/>training)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="59"><highlight class="normal"><sp/><sp/><sp/><sp/>@property</highlight></codeline>
<codeline lineno="60"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetGraph_1add4a8797de4c8b8a8236f75379fcba2d" kindref="member">testlogits</ref>(self):</highlight></codeline>
<codeline lineno="61"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>self.<ref refid="classnnetgraph_1_1NnetGraph_1a7865070847a47b7806f7e4fc4aa106d8" kindref="member">_testlogits</ref></highlight></codeline>
<codeline lineno="62"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="63"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##Saver<sp/>of<sp/>the<sp/>model<sp/>parameters</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="64"><highlight class="normal"><sp/><sp/><sp/><sp/>@property</highlight></codeline>
<codeline lineno="65"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetGraph_1afea62c57c4cd3f95909c2c82e5348618" kindref="member">saver</ref>(self):</highlight></codeline>
<codeline lineno="66"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>self.<ref refid="classnnetgraph_1_1NnetGraph_1a1ef39cef6fdae346a713524c94948fed" kindref="member">_saver</ref></highlight></codeline>
<codeline lineno="67"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="68"><highlight class="normal"><sp/><sp/><sp/><sp/>@inputs.setter</highlight></codeline>
<codeline lineno="69"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetGraph_1a5fb27655f740d4b9c2e99cf3bcb78547" kindref="member">inputs</ref>(self,<sp/>inputs):</highlight></codeline>
<codeline lineno="70"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetGraph_1a4954a87025ee4bbc4963773a292fb49a" kindref="member">_inputs</ref><sp/>=<sp/>inputs</highlight></codeline>
<codeline lineno="71"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="72"><highlight class="normal"><sp/><sp/><sp/><sp/>@outputs.setter</highlight></codeline>
<codeline lineno="73"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetGraph_1aeba1946cfab246f3475bd251c083dbf6" kindref="member">outputs</ref>(self,<sp/>outputs):</highlight></codeline>
<codeline lineno="74"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetGraph_1a080dd4e4e378af6a2667151807f20d64" kindref="member">_outputs</ref><sp/>=<sp/>outputs</highlight></codeline>
<codeline lineno="75"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="76"><highlight class="normal"><sp/><sp/><sp/><sp/>@trainlogits.setter</highlight></codeline>
<codeline lineno="77"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetGraph_1a7e52824ec329ad67a1f3c46e2167e784" kindref="member">trainlogits</ref>(self,<sp/>trainlogits):</highlight></codeline>
<codeline lineno="78"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetGraph_1a1b1357c29560703c90091644b859aff7" kindref="member">_trainlogits</ref><sp/>=<sp/>trainlogits</highlight></codeline>
<codeline lineno="79"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="80"><highlight class="normal"><sp/><sp/><sp/><sp/>@testlogits.setter</highlight></codeline>
<codeline lineno="81"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetGraph_1add4a8797de4c8b8a8236f75379fcba2d" kindref="member">testlogits</ref>(self,<sp/>testlogits):</highlight></codeline>
<codeline lineno="82"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetGraph_1a7865070847a47b7806f7e4fc4aa106d8" kindref="member">_testlogits</ref><sp/>=<sp/>testlogits</highlight></codeline>
<codeline lineno="83"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="84"><highlight class="normal"><sp/><sp/><sp/><sp/>@saver.setter</highlight></codeline>
<codeline lineno="85"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetGraph_1afea62c57c4cd3f95909c2c82e5348618" kindref="member">saver</ref>(self,<sp/>saver):</highlight></codeline>
<codeline lineno="86"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetGraph_1a1ef39cef6fdae346a713524c94948fed" kindref="member">_saver</ref><sp/>=<sp/>saver</highlight></codeline>
<codeline lineno="87"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="88"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="89"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="90"><highlight class="normal"></highlight><highlight class="comment">##This<sp/>class<sp/>is<sp/>a<sp/>graph<sp/>for<sp/>feedforward<sp/>fully<sp/>connected<sp/>neural<sp/>nets.<sp/>It<sp/>is<sp/>initialised<sp/>as<sp/>folows:<sp/>DNN(name,<sp/>input_dim,<sp/>output_dim,<sp/>num_hidden_layers,<sp/>num_hidden_units,<sp/>transfername,<sp/>l2_norm,<sp/>dropout)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="91"><highlight class="normal"></highlight><highlight class="comment">#<sp/><sp/><sp/>name:<sp/>name<sp/>of<sp/>the<sp/>DNN</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="92"><highlight class="normal"></highlight><highlight class="comment">#<sp/><sp/><sp/>input_dim:<sp/>the<sp/>input<sp/>dimension</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="93"><highlight class="normal"></highlight><highlight class="comment">#<sp/><sp/><sp/>output_dim:<sp/>the<sp/>output<sp/>dimension</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="94"><highlight class="normal"></highlight><highlight class="comment">#<sp/><sp/><sp/>num_hidden_layers:<sp/>number<sp/>of<sp/>hiden<sp/>layers<sp/>in<sp/>the<sp/>DNN</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="95"><highlight class="normal"></highlight><highlight class="comment">#<sp/><sp/><sp/>layer_wise_init:<sp/>Boolean<sp/>that<sp/>is<sp/>true<sp/>if<sp/>layerwhise<sp/>initialisation<sp/>should<sp/>be<sp/>done</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="96"><highlight class="normal"></highlight><highlight class="comment">#<sp/><sp/><sp/>num_hidden_units:<sp/>number<sp/>of<sp/>hidden<sp/>units<sp/>in<sp/>every<sp/>layer</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="97"><highlight class="normal"></highlight><highlight class="comment">#<sp/><sp/><sp/>transfername:<sp/>name<sp/>of<sp/>the<sp/>transfer<sp/>function<sp/>that<sp/>is<sp/>used</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="98"><highlight class="normal"></highlight><highlight class="comment">#<sp/><sp/><sp/>l2_norm:<sp/>boolean<sp/>that<sp/>determines<sp/>of<sp/>l2_normalisation<sp/>is<sp/>used<sp/>after<sp/>every<sp/>layer</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="99"><highlight class="normal"></highlight><highlight class="comment">#<sp/><sp/><sp/>dropout:<sp/>the<sp/>chance<sp/>that<sp/>a<sp/>hidden<sp/>unit<sp/>is<sp/>propagated<sp/>to<sp/>the<sp/>next<sp/>layer</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="100" refid="classnnetgraph_1_1DNN" refkind="compound"><highlight class="normal"></highlight><highlight class="keyword">class<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1DNN" kindref="compound">DNN</ref>(<ref refid="classnnetgraph_1_1NnetGraph" kindref="compound">NnetGraph</ref>):</highlight></codeline>
<codeline lineno="101"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="102"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##Extend<sp/>the<sp/>graph<sp/>with<sp/>the<sp/>DNN</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="103"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1DNN_1a6e498be1780113ea9c76d73190cfd836" kindref="member">extendGraph</ref>(self):</highlight></codeline>
<codeline lineno="104"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="105"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>with<sp/>tf.variable_scope(self.<ref refid="classnnetgraph_1_1NnetGraph_1a64645c360c6ebfc12489ce179f470053" kindref="member">name</ref>):</highlight></codeline>
<codeline lineno="106"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="107"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#define<sp/>the<sp/>input<sp/>data</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="108"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1DNN_1a2e78a1e255ddd7cb146aad694cf3b2a1" kindref="member">inputs</ref><sp/>=<sp/>tf.placeholder(tf.float32,<sp/>shape<sp/>=<sp/>[</highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/>self.input_dim],<sp/>name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;inputs&apos;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="109"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="110"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#placeholder<sp/>to<sp/>set<sp/>the<sp/>state<sp/>prior</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="111"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1DNN_1a0f32397414fff2f739513ed92b63174e" kindref="member">prior</ref><sp/>=<sp/>tf.placeholder(tf.float32,<sp/>shape<sp/>=<sp/>[self.output_dim],<sp/>name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;priorGate&apos;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="112"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="113"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#placeholder<sp/>to<sp/>set<sp/>the<sp/>state<sp/>prior</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="114"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>self.dropout<sp/>&lt;<sp/>1:</highlight></codeline>
<codeline lineno="115"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1DNN_1a2e754c90a59f470db6035aff1adf424b" kindref="member">applydropout</ref><sp/>=<sp/>tf.placeholder(tf.float32,<sp/>shape<sp/>=<sp/>[self.output_dim],<sp/>name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;priorGate&apos;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="116"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="117"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#variable<sp/>that<sp/>holds<sp/>the<sp/>state<sp/>prior</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="118"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>stateprior<sp/>=<sp/>tf.get_variable(</highlight><highlight class="stringliteral">&apos;prior&apos;</highlight><highlight class="normal">,<sp/>self.output_dim,<sp/>initializer=tf.constant_initializer(0),<sp/>trainable=</highlight><highlight class="keyword">False</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="119"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="120"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#variable<sp/>that<sp/>holds<sp/>the<sp/>state<sp/>prior</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="121"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>initialisedlayers<sp/>=<sp/>tf.get_variable(</highlight><highlight class="stringliteral">&apos;initialisedlayers&apos;</highlight><highlight class="normal">,<sp/>[],<sp/>initializer=tf.constant_initializer(0),<sp/>trainable=</highlight><highlight class="keyword">False</highlight><highlight class="normal">,<sp/>dtype=tf.int32)</highlight></codeline>
<codeline lineno="122"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="123"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#operation<sp/>to<sp/>increment<sp/>the<sp/>number<sp/>of<sp/>layers</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="124"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1DNN_1a6e6163b9726ed15d24aa1cb5a2a39168" kindref="member">addLayerOp</ref><sp/>=<sp/>initialisedlayers.assign_add(1).op</highlight></codeline>
<codeline lineno="125"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="126"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#operation<sp/>to<sp/>set<sp/>the<sp/>state<sp/>prior</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="127"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1DNN_1a4168866b75b244c010a3cdb9c1340eab" kindref="member">setPriorOp</ref><sp/>=<sp/>stateprior.assign(self.<ref refid="classnnetgraph_1_1DNN_1a0f32397414fff2f739513ed92b63174e" kindref="member">prior</ref>).op</highlight></codeline>
<codeline lineno="128"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="129"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#create<sp/>the<sp/>layers</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="130"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>layers<sp/>=<sp/>[</highlight><highlight class="keywordtype">None</highlight><highlight class="normal">]*(self.num_hidden_layers+1)</highlight></codeline>
<codeline lineno="131"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="132"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#input<sp/>layer</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="133"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>layers[0]<sp/>=<sp/><ref refid="classnnetlayer_1_1FFLayer" kindref="compound">nnetlayer.FFLayer</ref>(self.input_dim,<sp/>self.num_hidden_units,<sp/>1/np.sqrt(self.input_dim),<sp/></highlight><highlight class="stringliteral">&apos;layer0&apos;</highlight><highlight class="normal">,<sp/>self.transfername,<sp/>self.l2_norm,<sp/>self.dropout)</highlight></codeline>
<codeline lineno="134"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="135"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#hidden<sp/>layers</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="136"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>k<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>range(1,len(layers)-1):</highlight></codeline>
<codeline lineno="137"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>layers[k]<sp/>=<sp/><ref refid="classnnetlayer_1_1FFLayer" kindref="compound">nnetlayer.FFLayer</ref>(self.num_hidden_units,<sp/>self.num_hidden_units,<sp/>1/np.sqrt(self.num_hidden_units),<sp/></highlight><highlight class="stringliteral">&apos;layer&apos;</highlight><highlight class="normal"><sp/>+<sp/>str(k),<sp/>self.transfername,<sp/>self.l2_norm,<sp/>self.dropout)</highlight></codeline>
<codeline lineno="138"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="139"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#output<sp/>layer</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="140"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>layers[-1]<sp/>=<sp/><ref refid="classnnetlayer_1_1FFLayer" kindref="compound">nnetlayer.FFLayer</ref>(self.num_hidden_units,<sp/>self.output_dim,<sp/>0,<sp/></highlight><highlight class="stringliteral">&apos;layer&apos;</highlight><highlight class="normal"><sp/>+<sp/>str(len(layers)-1))</highlight></codeline>
<codeline lineno="141"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="142"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#operation<sp/>to<sp/>initialise<sp/>the<sp/>final<sp/>layer</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="143"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1DNN_1a1f8ba580cbb24bad9d0166f296b524b1" kindref="member">initLastLayerOp</ref><sp/>=<sp/>tf.initialize_variables([layers[-1].weights,<sp/>layers[-1].biases])</highlight></codeline>
<codeline lineno="144"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="145"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#do<sp/>the<sp/>forward<sp/>computation<sp/>with<sp/>dropout</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="146"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="147"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>activations<sp/>=<sp/>[</highlight><highlight class="keywordtype">None</highlight><highlight class="normal">]*(len(layers)-1)</highlight></codeline>
<codeline lineno="148"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>activations[0]=<sp/>layers[0](self.<ref refid="classnnetgraph_1_1DNN_1a2e78a1e255ddd7cb146aad694cf3b2a1" kindref="member">inputs</ref>)</highlight></codeline>
<codeline lineno="149"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>l<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>range(1,len(activations)):</highlight></codeline>
<codeline lineno="150"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>activations[l]<sp/>=<sp/>layers[l](activations[l-1])</highlight></codeline>
<codeline lineno="151"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="152"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>self.layer_wise_init:</highlight></codeline>
<codeline lineno="153"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#compute<sp/>the<sp/>logits<sp/>by<sp/>selecting<sp/>the<sp/>activations<sp/>at<sp/>the<sp/>layer<sp/>that<sp/>has<sp/>last<sp/>been<sp/>added<sp/>to<sp/>the<sp/>network,<sp/>this<sp/>is<sp/>used<sp/>for<sp/>layer<sp/>by<sp/>layer<sp/>initialisation</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="154"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1DNN_1ac4075e7063abdc28971340fb7f4c2340" kindref="member">trainlogits</ref><sp/>=<sp/>layers[-1](tf.case([(tf.equal(initialisedlayers,<sp/>tf.constant(l)),<sp/><ref refid="classnnetgraph_1_1CallableTensor" kindref="compound">CallableTensor</ref>(activations[l]))<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>l<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>range(len(activations))],<sp/><ref refid="classnnetgraph_1_1CallableTensor" kindref="compound">CallableTensor</ref>(activations[-1]),name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;layerSelector&apos;</highlight><highlight class="normal">))</highlight></codeline>
<codeline lineno="155"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="156"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1DNN_1ac4075e7063abdc28971340fb7f4c2340" kindref="member">trainlogits</ref><sp/>=<sp/>layers[-1](activations[-1])</highlight></codeline>
<codeline lineno="157"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="158"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#do<sp/>the<sp/>forward<sp/>computation<sp/>without<sp/>dropout</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="159"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="160"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>activations<sp/>=<sp/>[</highlight><highlight class="keywordtype">None</highlight><highlight class="normal">]*(len(layers)-1)</highlight></codeline>
<codeline lineno="161"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>activations[0]=<sp/>layers[0](self.<ref refid="classnnetgraph_1_1DNN_1a2e78a1e255ddd7cb146aad694cf3b2a1" kindref="member">inputs</ref>,<sp/></highlight><highlight class="keyword">False</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="162"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>l<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>range(1,len(activations)):</highlight></codeline>
<codeline lineno="163"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>activations[l]<sp/>=<sp/>layers[l](activations[l-1],<sp/></highlight><highlight class="keyword">False</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="164"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="165"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>self.layer_wise_init:</highlight></codeline>
<codeline lineno="166"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#compute<sp/>the<sp/>logits<sp/>by<sp/>selecting<sp/>the<sp/>activations<sp/>at<sp/>the<sp/>layer<sp/>that<sp/>has<sp/>last<sp/>been<sp/>added<sp/>to<sp/>the<sp/>network,<sp/>this<sp/>is<sp/>used<sp/>for<sp/>layer<sp/>by<sp/>layer<sp/>initialisation</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="167"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1DNN_1a6a03d2a8afd75ede3b9949679cc92200" kindref="member">testlogits</ref><sp/>=<sp/>layers[-1](tf.case([(tf.equal(initialisedlayers,<sp/>tf.constant(l)),<sp/><ref refid="classnnetgraph_1_1CallableTensor" kindref="compound">CallableTensor</ref>(activations[l]))<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>l<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>range(len(activations))],<sp/><ref refid="classnnetgraph_1_1CallableTensor" kindref="compound">CallableTensor</ref>(activations[-1]),name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;layerSelector&apos;</highlight><highlight class="normal">),<sp/></highlight><highlight class="keyword">False</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="168"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="169"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1DNN_1a6a03d2a8afd75ede3b9949679cc92200" kindref="member">testlogits</ref><sp/>=<sp/>layers[-1](activations[-1],<sp/></highlight><highlight class="keyword">False</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="170"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="171"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#define<sp/>the<sp/>output<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="172"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1DNN_1a7049bad6c0f97c992794499499a771b1" kindref="member">outputs</ref><sp/>=<sp/>tf.nn.softmax(self.<ref refid="classnnetgraph_1_1DNN_1a6a03d2a8afd75ede3b9949679cc92200" kindref="member">testlogits</ref>)/stateprior</highlight></codeline>
<codeline lineno="173"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="174"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#create<sp/>a<sp/>saver<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="175"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1DNN_1a887babe5c6099bbb5bdf9e7db2177c28" kindref="member">saver</ref><sp/>=<sp/>tf.train.Saver()</highlight></codeline>
<codeline lineno="176"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="177"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##set<sp/>the<sp/>prior<sp/>in<sp/>the<sp/>graph</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="178"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="179"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>prior<sp/>the<sp/>state<sp/>prior<sp/>probabilities</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="180"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1DNN_1ab842f9cba9196a99709302e19938ce1f" kindref="member">setPrior</ref>(self,<sp/>prior):</highlight></codeline>
<codeline lineno="181"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.setPriorOp.run(feed_dict={self.<ref refid="classnnetgraph_1_1DNN_1a0f32397414fff2f739513ed92b63174e" kindref="member">prior</ref>:prior})</highlight></codeline>
<codeline lineno="182"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="183"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##Add<sp/>a<sp/>layer<sp/>to<sp/>the<sp/>network</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="184"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1DNN_1a72399cd0f0574558ebe7982694ca4038" kindref="member">addLayer</ref>(self):</highlight></codeline>
<codeline lineno="185"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#reinitialise<sp/>the<sp/>final<sp/>layer</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="186"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.initLastLayerOp.run()</highlight></codeline>
<codeline lineno="187"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="188"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#increment<sp/>the<sp/>number<sp/>of<sp/>layers</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="189"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.addLayerOp.run()</highlight></codeline>
<codeline lineno="190"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="191"><highlight class="normal"><sp/><sp/><sp/><sp/>@property</highlight></codeline>
<codeline lineno="192"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal">fieldnames(self):</highlight></codeline>
<codeline lineno="193"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>[</highlight><highlight class="stringliteral">&apos;input_dim&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;output_dim&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;num_hidden_layers&apos;</highlight><highlight class="normal">,<sp/><sp/></highlight><highlight class="stringliteral">&apos;layer_wise_init&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;num_hidden_units&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;transfername&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;l2_norm&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;dropout&apos;</highlight><highlight class="normal">]</highlight></codeline>
<codeline lineno="194"><highlight class="normal"></highlight></codeline>
<codeline lineno="195"><highlight class="normal"></highlight><highlight class="comment">##Class<sp/>for<sp/>the<sp/>decoding<sp/>environment<sp/>for<sp/>a<sp/>neural<sp/>net<sp/>graph</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="196" refid="classnnetgraph_1_1NnetDecoder" refkind="compound"><highlight class="normal"></highlight><highlight class="keyword">class<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetDecoder" kindref="compound">NnetDecoder</ref>(object):</highlight></codeline>
<codeline lineno="197"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##NnetDecoder<sp/>constructor,<sp/>creates<sp/>the<sp/>decoding<sp/>graph</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="198"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="199"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>nnetgraph<sp/>an<sp/>nnetgraph<sp/>object<sp/>for<sp/>the<sp/>neural<sp/>net<sp/>that<sp/>will<sp/>be<sp/>used<sp/>for<sp/>decoding</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="200"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetDecoder_1a5b0019a01c530f82d46ce492e717cfd4" kindref="member">__init__</ref>(self,<sp/>nnetGraph):</highlight></codeline>
<codeline lineno="201"><highlight class="normal"></highlight></codeline>
<codeline lineno="202"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetDecoder_1a0264f04b0edda1512a61320708e22dce" kindref="member">graph</ref><sp/>=<sp/>tf.Graph()</highlight></codeline>
<codeline lineno="203"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetDecoder_1a1b67af250a03f7c0cbe0cc27b6850d23" kindref="member">nnetGraph</ref><sp/>=<sp/>nnetGraph</highlight></codeline>
<codeline lineno="204"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="205"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>with<sp/>self.graph.as_default():</highlight></codeline>
<codeline lineno="206"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="207"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#create<sp/>the<sp/>decoding<sp/>graph</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="208"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.nnetGraph.extendGraph()</highlight></codeline>
<codeline lineno="209"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="210"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#specify<sp/>that<sp/>the<sp/>graph<sp/>can<sp/>no<sp/>longer<sp/>be<sp/>modified<sp/>after<sp/>this<sp/>point</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="211"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.graph.finalize()</highlight></codeline>
<codeline lineno="212"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="213"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##decode<sp/>using<sp/>the<sp/>neural<sp/>net</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="214"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="215"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>inputs<sp/>the<sp/>inputs<sp/>to<sp/>the<sp/>graph<sp/>as<sp/>a<sp/>NxF<sp/>numpy<sp/>array<sp/>where<sp/>N<sp/>is<sp/>the<sp/>number<sp/>of<sp/>frames<sp/>and<sp/>F<sp/>is<sp/>the<sp/>input<sp/>feature<sp/>dimension</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="216"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="217"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@return<sp/>an<sp/>NxO<sp/>numpy<sp/>array<sp/>where<sp/>N<sp/>is<sp/>the<sp/>number<sp/>of<sp/>frames<sp/>and<sp/>O<sp/>is<sp/>the<sp/>neural<sp/>net<sp/>output<sp/>dimension</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="218"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetDecoder_1a916b8ffed8f8dcafb47ff9c61ba886d5" kindref="member">__call__</ref>(self,<sp/>inputs):</highlight></codeline>
<codeline lineno="219"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>self.nnetGraph.outputs.eval(feed_dict<sp/>=<sp/>{self.nnetGraph.inputs:inputs})</highlight></codeline>
<codeline lineno="220"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="221"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##load<sp/>the<sp/>saved<sp/>neural<sp/>net</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="222"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="223"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>filename<sp/>location<sp/>where<sp/>the<sp/>neural<sp/>net<sp/>is<sp/>saved</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="224"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetDecoder_1a33ae73b18d9f6f353da08f4a9aadf686" kindref="member">restore</ref>(self,<sp/>filename):</highlight></codeline>
<codeline lineno="225"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.nnetGraph.saver.restore(tf.get_default_session(),<sp/>filename)</highlight></codeline>
<codeline lineno="226"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="227"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="228"><highlight class="normal"></highlight><highlight class="comment">##Class<sp/>for<sp/>the<sp/>training<sp/>environment<sp/>for<sp/>a<sp/>neural<sp/>net<sp/>graph</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="229" refid="classnnetgraph_1_1NnetTrainer" refkind="compound"><highlight class="normal"></highlight><highlight class="keyword">class<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetTrainer" kindref="compound">NnetTrainer</ref>(object):</highlight></codeline>
<codeline lineno="230"><highlight class="normal"></highlight></codeline>
<codeline lineno="231"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#NnetTrainer<sp/>constructor,<sp/>creates<sp/>the<sp/>training<sp/>graph</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="232"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="233"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>nnetgraph<sp/>an<sp/>nnetgraph<sp/>object<sp/>for<sp/>the<sp/>neural<sp/>net<sp/>that<sp/>will<sp/>be<sp/>used<sp/>for<sp/>decoding</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="234"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>init_learning_rate<sp/>the<sp/>initial<sp/>learning<sp/>rate</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="235"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>learning_rate_decay<sp/>the<sp/>parameter<sp/>for<sp/>exponential<sp/>learning<sp/>rate<sp/>decay</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="236"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>num_steps<sp/>the<sp/>total<sp/>number<sp/>of<sp/>steps<sp/>that<sp/>will<sp/>be<sp/>taken</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="237"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>numframes_per_batch<sp/>determines<sp/>how<sp/>many<sp/>frames<sp/>are<sp/>processed<sp/>at<sp/>a<sp/>time<sp/>to<sp/>limit<sp/>memory<sp/>usage</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="238"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal">__init__(self,<sp/>nnetGraph,<sp/>init_learning_rate,<sp/>learning_rate_decay,<sp/>num_steps,<sp/>numframes_per_batch):</highlight></codeline>
<codeline lineno="239"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="240"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a206fa47fd1d8fbf5d723811b1bbc0bee" kindref="member">numframes_per_batch</ref><sp/>=<sp/>numframes_per_batch</highlight></codeline>
<codeline lineno="241"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1af0b8647b2d0c3b6977d0c8ce3825864a" kindref="member">nnetGraph</ref><sp/>=<sp/>nnetGraph</highlight></codeline>
<codeline lineno="242"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="243"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#create<sp/>the<sp/>graph</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="244"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a04443a9dcee9bc5be8687d261e1170d5" kindref="member">graph</ref><sp/>=<sp/>tf.Graph()</highlight></codeline>
<codeline lineno="245"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="246"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#define<sp/>the<sp/>placeholders<sp/>in<sp/>the<sp/>graph</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="247"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>with<sp/>self.graph.as_default():</highlight></codeline>
<codeline lineno="248"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="249"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#create<sp/>the<sp/>decoding<sp/>graph</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="250"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.nnetGraph.extendGraph()</highlight></codeline>
<codeline lineno="251"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="252"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#reference<sp/>labels</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="253"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a5b7207158a2a66c947912adeb23a8559" kindref="member">targets</ref><sp/>=<sp/>tf.placeholder(tf.float32,<sp/>shape<sp/>=<sp/>[</highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/>self.nnetGraph.trainlogits.get_shape().as_list()[1]],<sp/>name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;targets&apos;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="254"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="255"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#input<sp/>for<sp/>the<sp/>total<sp/>number<sp/>of<sp/>frames<sp/>that<sp/>are<sp/>used<sp/>in<sp/>the<sp/>batch</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="256"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1abb8e4f89811de6b61fbec9a428f3bb21" kindref="member">num_frames</ref><sp/>=<sp/>tf.placeholder(tf.float32,<sp/>shape<sp/>=<sp/>[],<sp/>name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;num_frames&apos;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="257"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="258"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#get<sp/>a<sp/>list<sp/>of<sp/>trainable<sp/>variables<sp/>in<sp/>the<sp/>decoder<sp/>graph</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="259"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>params<sp/>=<sp/>tf.trainable_variables()</highlight></codeline>
<codeline lineno="260"><highlight class="normal"></highlight></codeline>
<codeline lineno="261"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#add<sp/>the<sp/>variables<sp/>and<sp/>operations<sp/>to<sp/>the<sp/>graph<sp/>that<sp/>are<sp/>used<sp/>for<sp/>training</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="262"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="263"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#compute<sp/>the<sp/>training<sp/>loss</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="264"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a065207f0782e739c51e459b4c0053f2e" kindref="member">loss</ref><sp/>=<sp/>tf.reduce_sum(self.<ref refid="classnnetgraph_1_1NnetTrainer_1af663b9f0a8ff41b9caa2d119deb41566" kindref="member">computeLoss</ref>(self.<ref refid="classnnetgraph_1_1NnetTrainer_1a5b7207158a2a66c947912adeb23a8559" kindref="member">targets</ref>,<sp/>self.nnetGraph.trainlogits))</highlight></codeline>
<codeline lineno="265"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="266"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#compute<sp/>the<sp/>validation<sp/>loss</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="267"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1ae968321ba2af8c85ae935bf10a3fe2f0" kindref="member">validLoss</ref><sp/>=<sp/>tf.reduce_sum(self.<ref refid="classnnetgraph_1_1NnetTrainer_1af663b9f0a8ff41b9caa2d119deb41566" kindref="member">computeLoss</ref>(self.<ref refid="classnnetgraph_1_1NnetTrainer_1a5b7207158a2a66c947912adeb23a8559" kindref="member">targets</ref>,<sp/>self.nnetGraph.testlogits))</highlight></codeline>
<codeline lineno="268"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="269"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#total<sp/>number<sp/>of<sp/>steps</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="270"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Nsteps<sp/>=<sp/>tf.constant(num_steps,<sp/>dtype<sp/>=<sp/>tf.int32,<sp/>name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;num_steps&apos;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="271"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="272"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#the<sp/>total<sp/>loss<sp/>of<sp/>the<sp/>entire<sp/>batch</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="273"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>batch_loss<sp/>=<sp/>tf.get_variable(</highlight><highlight class="stringliteral">&apos;batch_loss&apos;</highlight><highlight class="normal">,<sp/>[],<sp/>dtype=tf.float32,<sp/>initializer=tf.constant_initializer(0),<sp/>trainable=</highlight><highlight class="keyword">False</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="274"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="275"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#operation<sp/>to<sp/>update<sp/>the<sp/>validation<sp/>loss</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="276"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1aeaed9bbaaff5c0b85fff266fcd1e6c98" kindref="member">updateValidLoss</ref><sp/>=<sp/>batch_loss.assign_add(self.<ref refid="classnnetgraph_1_1NnetTrainer_1ae968321ba2af8c85ae935bf10a3fe2f0" kindref="member">validLoss</ref>).op</highlight></codeline>
<codeline lineno="277"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="278"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>with<sp/>tf.variable_scope(</highlight><highlight class="stringliteral">&apos;train_variables&apos;</highlight><highlight class="normal">):<sp/><sp/></highlight></codeline>
<codeline lineno="279"><highlight class="normal"></highlight></codeline>
<codeline lineno="280"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#the<sp/>amount<sp/>of<sp/>steps<sp/>already<sp/>taken</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="281"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a5cc20718f43b067f465c00c0bab41c94" kindref="member">global_step</ref><sp/>=<sp/>tf.get_variable(</highlight><highlight class="stringliteral">&apos;global_step&apos;</highlight><highlight class="normal">,<sp/>[],<sp/>dtype=tf.int32,<sp/>initializer=tf.constant_initializer(0),<sp/>trainable=</highlight><highlight class="keyword">False</highlight><highlight class="normal">)<sp/></highlight></codeline>
<codeline lineno="282"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="283"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#a<sp/>variable<sp/>to<sp/>scale<sp/>the<sp/>learning<sp/>rate<sp/>(used<sp/>to<sp/>reduce<sp/>the<sp/>learning<sp/>rate<sp/>in<sp/>case<sp/>validation<sp/>performance<sp/>drops)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="284"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>learning_rate_fact<sp/>=<sp/>tf.get_variable(</highlight><highlight class="stringliteral">&apos;learning_rate_fact&apos;</highlight><highlight class="normal">,<sp/>[],<sp/>initializer=tf.constant_initializer(1.0),<sp/>trainable=</highlight><highlight class="keyword">False</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="285"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="286"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#compute<sp/>the<sp/>learning<sp/>rate<sp/>with<sp/>exponential<sp/>decay<sp/>and<sp/>scale<sp/>with<sp/>the<sp/>learning<sp/>rate<sp/>factor</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="287"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>learning_rate<sp/>=<sp/>tf.train.exponential_decay(init_learning_rate,<sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a5cc20718f43b067f465c00c0bab41c94" kindref="member">global_step</ref>,<sp/>Nsteps,<sp/>learning_rate_decay)<sp/>*<sp/>learning_rate_fact</highlight></codeline>
<codeline lineno="288"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="289"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#create<sp/>the<sp/>optimizer</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="290"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>optimizer<sp/>=<sp/>tf.train.AdamOptimizer(learning_rate)</highlight></codeline>
<codeline lineno="291"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="292"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#for<sp/>every<sp/>parameter<sp/>create<sp/>a<sp/>variable<sp/>that<sp/>holds<sp/>its<sp/>gradients</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="293"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>with<sp/>tf.variable_scope(</highlight><highlight class="stringliteral">&apos;gradients&apos;</highlight><highlight class="normal">):</highlight></codeline>
<codeline lineno="294"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>grads<sp/>=<sp/>[tf.get_variable(param.op.name,<sp/>param.get_shape().as_list(),<sp/>initializer=tf.constant_initializer(0),<sp/>trainable=</highlight><highlight class="keyword">False</highlight><highlight class="normal">)<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>param<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>params]</highlight></codeline>
<codeline lineno="295"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="296"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>with<sp/>tf.name_scope(</highlight><highlight class="stringliteral">&apos;train&apos;</highlight><highlight class="normal">):</highlight></codeline>
<codeline lineno="297"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#operation<sp/>to<sp/>half<sp/>the<sp/>learning<sp/>rate</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="298"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a42fab19fcc0c84dac53bebeff065bf4b" kindref="member">halveLearningRateOp</ref><sp/>=<sp/>learning_rate_fact.assign(learning_rate_fact/2).op</highlight></codeline>
<codeline lineno="299"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="300"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#create<sp/>an<sp/>operation<sp/>to<sp/>initialise<sp/>the<sp/>gradients</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="301"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1af06f5c79d095b45246157608128a0e8f" kindref="member">initgrads</ref><sp/>=<sp/>tf.initialize_variables(grads)</highlight></codeline>
<codeline lineno="302"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="303"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#the<sp/>operation<sp/>to<sp/>initialise<sp/>the<sp/>batch<sp/>loss</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="304"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1af202c94295526b38014b758e41a69a2f" kindref="member">initloss</ref><sp/>=<sp/>batch_loss.initializer</highlight></codeline>
<codeline lineno="305"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="306"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#compute<sp/>the<sp/>gradients<sp/>of<sp/>the<sp/>batch</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="307"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>batchgrads<sp/>=<sp/>tf.gradients(self.<ref refid="classnnetgraph_1_1NnetTrainer_1a065207f0782e739c51e459b4c0053f2e" kindref="member">loss</ref>,<sp/>params)</highlight></codeline>
<codeline lineno="308"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="309"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#create<sp/>an<sp/>operation<sp/>to<sp/>update<sp/>the<sp/>batch<sp/>loss</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="310"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a969cd8fdf92472e1f1e2339c0299374e" kindref="member">updateLoss</ref><sp/>=<sp/>batch_loss.assign_add(self.<ref refid="classnnetgraph_1_1NnetTrainer_1a065207f0782e739c51e459b4c0053f2e" kindref="member">loss</ref>).op</highlight></codeline>
<codeline lineno="311"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="312"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#create<sp/>an<sp/>operation<sp/>to<sp/>update<sp/>the<sp/>gradients<sp/>and<sp/>the<sp/>batch_loss</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="313"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1ab7b76665bcaa7f95b12ff22f3b0d7333" kindref="member">updateGradientsOp</ref><sp/>=<sp/>tf.group(*([grads[p].assign_add(batchgrads[p])<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>p<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>range(len(grads))<sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>batchgrads[p]<sp/></highlight><highlight class="keywordflow">is</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">]<sp/>+<sp/>[self.<ref refid="classnnetgraph_1_1NnetTrainer_1a969cd8fdf92472e1f1e2339c0299374e" kindref="member">updateLoss</ref>]),<sp/>name=</highlight><highlight class="stringliteral">&apos;update_gradients&apos;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="314"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="315"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#create<sp/>an<sp/>operation<sp/>to<sp/>apply<sp/>the<sp/>gradients</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="316"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a4bcbddf26035f57c24c82e86e8ebb7b6" kindref="member">applyGradientsOp</ref><sp/>=<sp/>optimizer.apply_gradients([(grads[p]/self.<ref refid="classnnetgraph_1_1NnetTrainer_1abb8e4f89811de6b61fbec9a428f3bb21" kindref="member">num_frames</ref>,<sp/>params[p])<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>p<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>range(len(grads))],<sp/>global_step=self.<ref refid="classnnetgraph_1_1NnetTrainer_1a5cc20718f43b067f465c00c0bab41c94" kindref="member">global_step</ref>,<sp/>name=</highlight><highlight class="stringliteral">&apos;apply_gradients&apos;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="317"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="318"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>add<sp/>an<sp/>operation<sp/>to<sp/>initialise<sp/>all<sp/>the<sp/>variables<sp/>in<sp/>the<sp/>graph</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="319"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a69244a57c16590c14bb855b8ce061b3f" kindref="member">initop</ref><sp/>=<sp/>tf.initialize_all_variables()</highlight></codeline>
<codeline lineno="320"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="321"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#operation<sp/>to<sp/>compute<sp/>the<sp/>average<sp/>loss<sp/>in<sp/>the<sp/>batch</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="322"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a27e5a85e4128672feedf9920f43dac50" kindref="member">average_loss</ref><sp/>=<sp/>batch_loss/self.<ref refid="classnnetgraph_1_1NnetTrainer_1abb8e4f89811de6b61fbec9a428f3bb21" kindref="member">num_frames</ref></highlight></codeline>
<codeline lineno="323"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="324"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#saver<sp/>for<sp/>the<sp/>training<sp/>variables</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="325"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1ad593ba7c354bebc4532f29bc83ff0ab8" kindref="member">saver</ref><sp/>=<sp/>tf.train.Saver(tf.get_collection(tf.GraphKeys.VARIABLES,<sp/>scope=</highlight><highlight class="stringliteral">&apos;train_variables&apos;</highlight><highlight class="normal">))</highlight></codeline>
<codeline lineno="326"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="327"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#create<sp/>the<sp/>summaries<sp/>for<sp/>visualisation</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="328"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1aed8cbf0444c8341d305bc95341955759" kindref="member">summary</ref><sp/>=<sp/>tf.merge_summary([tf.histogram_summary(val.name,<sp/>val)<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>val<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>params+grads]<sp/>+<sp/>[tf.scalar_summary(</highlight><highlight class="stringliteral">&apos;loss&apos;</highlight><highlight class="normal">,<sp/>batch_loss)])</highlight></codeline>
<codeline lineno="329"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="330"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="331"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#specify<sp/>that<sp/>the<sp/>graph<sp/>can<sp/>no<sp/>longer<sp/>be<sp/>modified<sp/>after<sp/>this<sp/>point</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="332"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.graph.finalize()</highlight></codeline>
<codeline lineno="333"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="334"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#start<sp/>without<sp/>visualisation</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="335"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1ae5a2fd08bc29f191c9a0c71cd8a1e84b" kindref="member">summarywriter</ref><sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="336"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="337"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##Creates<sp/>the<sp/>operation<sp/>to<sp/>compute<sp/>the<sp/>cross-enthropy<sp/>loss<sp/>for<sp/>every<sp/>input<sp/>frame<sp/>(if<sp/>you<sp/>want<sp/>to<sp/>have<sp/>a<sp/>different<sp/>loss<sp/>function,<sp/>overwrite<sp/>this<sp/>method)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="338"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="339"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>targets<sp/>a<sp/>NxO<sp/>tensor<sp/>containing<sp/>the<sp/>reference<sp/>targets<sp/>where<sp/>N<sp/>is<sp/>the<sp/>number<sp/>of<sp/>frames<sp/>and<sp/>O<sp/>is<sp/>the<sp/>neural<sp/>net<sp/>output<sp/>dimension</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="340"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>logits<sp/>a<sp/>NxO<sp/>tensor<sp/>containing<sp/>the<sp/>neural<sp/>network<sp/>output<sp/>logits<sp/>where<sp/>N<sp/>is<sp/>the<sp/>number<sp/>of<sp/>frames<sp/>and<sp/>O<sp/>is<sp/>the<sp/>neural<sp/>net<sp/>output<sp/>dimension</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="341"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="342"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@return<sp/>an<sp/>N-dimensional<sp/>tensor<sp/>containing<sp/>the<sp/>losses<sp/>for<sp/>all<sp/>the<sp/>input<sp/>frames<sp/>where<sp/>N<sp/>is<sp/>the<sp/>number<sp/>of<sp/>frames</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="343"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetTrainer_1af663b9f0a8ff41b9caa2d119deb41566" kindref="member">computeLoss</ref>(self,<sp/>targets,<sp/>logits):</highlight></codeline>
<codeline lineno="344"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>tf.nn.softmax_cross_entropy_with_logits(logits,<sp/>targets,<sp/>name=</highlight><highlight class="stringliteral">&apos;loss&apos;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="345"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="346"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##Initialize<sp/>all<sp/>the<sp/>variables<sp/>in<sp/>the<sp/>graph</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="347"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetTrainer_1aed652d306480d80fd23e1f920f7b1545" kindref="member">initialize</ref>(self):</highlight></codeline>
<codeline lineno="348"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.initop.run()</highlight></codeline>
<codeline lineno="349"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="350"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##open<sp/>a<sp/>summarywriter<sp/>for<sp/>visualisation<sp/>and<sp/>add<sp/>the<sp/>graph</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="351"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="352"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>logdir<sp/>directory<sp/>where<sp/>the<sp/>summaries<sp/>will<sp/>be<sp/>written</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="353"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetTrainer_1acd1fabc849c35363826dbb53a2cedf3a" kindref="member">startVisualization</ref>(self,<sp/>logdir):</highlight></codeline>
<codeline lineno="354"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1ae5a2fd08bc29f191c9a0c71cd8a1e84b" kindref="member">summarywriter</ref><sp/>=<sp/>tf.train.SummaryWriter(logdir=logdir,<sp/>graph=self.<ref refid="classnnetgraph_1_1NnetTrainer_1a04443a9dcee9bc5be8687d261e1170d5" kindref="member">graph</ref>)</highlight></codeline>
<codeline lineno="355"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="356"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##update<sp/>the<sp/>neural<sp/>model<sp/>with<sp/>a<sp/>batch<sp/>or<sp/>training<sp/>data</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="357"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="358"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>inputs<sp/>the<sp/>inputs<sp/>to<sp/>the<sp/>neural<sp/>net,<sp/>this<sp/>should<sp/>be<sp/>a<sp/>NxF<sp/>numpy<sp/>array<sp/>where<sp/>N<sp/>is<sp/>the<sp/>number<sp/>of<sp/>frames<sp/>in<sp/>the<sp/>batch<sp/>and<sp/>F<sp/>is<sp/>the<sp/>feature<sp/>dimension</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="359"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>targets<sp/>the<sp/>one-hot<sp/>encoded<sp/>targets<sp/>for<sp/>neural<sp/>nnet,<sp/>this<sp/>should<sp/>be<sp/>an<sp/>NxO<sp/>matrix<sp/>where<sp/>O<sp/>is<sp/>the<sp/>output<sp/>dimension<sp/>of<sp/>the<sp/>neural<sp/>net</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="360"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="361"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@return<sp/>the<sp/>loss<sp/>at<sp/>this<sp/>step</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="362"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetTrainer_1aedfa8af303dab0f0ccc84f48f2d7b729" kindref="member">update</ref>(self,<sp/>inputs,<sp/>targets):</highlight></codeline>
<codeline lineno="363"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="364"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#if<sp/>numframes_per_batch<sp/>is<sp/>not<sp/>set<sp/>just<sp/>process<sp/>the<sp/>entire<sp/>batch</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="365"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a206fa47fd1d8fbf5d723811b1bbc0bee" kindref="member">numframes_per_batch</ref>==-1<sp/></highlight><highlight class="keywordflow">or</highlight><highlight class="normal"><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a206fa47fd1d8fbf5d723811b1bbc0bee" kindref="member">numframes_per_batch</ref>&gt;inputs.shape[0]:</highlight></codeline>
<codeline lineno="366"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>numframes_per_batch<sp/>=<sp/>inputs.shape[0]</highlight></codeline>
<codeline lineno="367"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="368"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>numframes_per_batch<sp/>=<sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a206fa47fd1d8fbf5d723811b1bbc0bee" kindref="member">numframes_per_batch</ref></highlight></codeline>
<codeline lineno="369"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="370"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#feed<sp/>in<sp/>the<sp/>batches<sp/>one<sp/>by<sp/>one<sp/>and<sp/>accumulate<sp/>the<sp/>gradients<sp/>and<sp/>loss</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="371"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>k<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>range(int(inputs.shape[0]/numframes_per_batch)<sp/>+<sp/>int(inputs.shape[0]%numframes_per_batch<sp/>&gt;<sp/>0)):</highlight></codeline>
<codeline lineno="372"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>batchInputs<sp/>=<sp/>inputs[k*numframes_per_batch:min((k+1)*numframes_per_batch,<sp/>inputs.shape[0]),<sp/>:]</highlight></codeline>
<codeline lineno="373"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>batchTargets<sp/>=<sp/>targets[k*numframes_per_batch:min((k+1)*numframes_per_batch,<sp/>inputs.shape[0]),<sp/>:]</highlight></codeline>
<codeline lineno="374"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.updateGradientsOp.run(feed_dict<sp/>=<sp/>{self.nnetGraph.inputs:batchInputs,<sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a5b7207158a2a66c947912adeb23a8559" kindref="member">targets</ref>:batchTargets})</highlight></codeline>
<codeline lineno="375"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="376"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#apply<sp/>the<sp/>accumulated<sp/>gradients<sp/>to<sp/>update<sp/>the<sp/>model<sp/>parameters</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="377"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.applyGradientsOp.run(feed_dict<sp/>=<sp/>{self.<ref refid="classnnetgraph_1_1NnetTrainer_1abb8e4f89811de6b61fbec9a428f3bb21" kindref="member">num_frames</ref>:inputs.shape[0]})</highlight></codeline>
<codeline lineno="378"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="379"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#get<sp/>the<sp/>loss<sp/>at<sp/>this<sp/>step</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="380"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>loss<sp/>=<sp/>self.average_loss.eval(feed_dict<sp/>=<sp/>{self.<ref refid="classnnetgraph_1_1NnetTrainer_1abb8e4f89811de6b61fbec9a428f3bb21" kindref="member">num_frames</ref>:inputs.shape[0]})</highlight></codeline>
<codeline lineno="381"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="382"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#if<sp/>visualization<sp/>has<sp/>started<sp/>add<sp/>the<sp/>summary</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="383"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1ae5a2fd08bc29f191c9a0c71cd8a1e84b" kindref="member">summarywriter</ref><sp/></highlight><highlight class="keywordflow">is</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="384"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.summarywriter.add_summary(self.summary.eval(),<sp/>global_step=self.global_step.eval())</highlight></codeline>
<codeline lineno="385"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="386"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#reinitialize<sp/>the<sp/>gradients<sp/>and<sp/>the<sp/>loss</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="387"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.initgrads.run()</highlight></codeline>
<codeline lineno="388"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.initloss.run()</highlight></codeline>
<codeline lineno="389"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="390"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>loss</highlight></codeline>
<codeline lineno="391"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="392"><highlight class="normal"></highlight></codeline>
<codeline lineno="393"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##Evaluate<sp/>the<sp/>performance<sp/>of<sp/>the<sp/>neural<sp/>net</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="394"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="395"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>inputs<sp/>the<sp/>inputs<sp/>to<sp/>the<sp/>neural<sp/>net,<sp/>this<sp/>should<sp/>be<sp/>a<sp/>NxF<sp/>numpy<sp/>array<sp/>where<sp/>N<sp/>is<sp/>the<sp/>number<sp/>of<sp/>frames<sp/>in<sp/>the<sp/>batch<sp/>and<sp/>F<sp/>is<sp/>the<sp/>feature<sp/>dimension</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="396"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>targets<sp/>the<sp/>one-hot<sp/>encoded<sp/>targets<sp/>for<sp/>neural<sp/>nnet,<sp/>this<sp/>should<sp/>be<sp/>an<sp/>NxO<sp/>matrix<sp/>where<sp/>O<sp/>is<sp/>the<sp/>output<sp/>dimension<sp/>of<sp/>the<sp/>neural<sp/>net</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="397"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="398"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@return<sp/>the<sp/>loss<sp/>of<sp/>the<sp/>batch</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="399"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetTrainer_1a452cd3c0bca96de8bb264e9881f27cb4" kindref="member">evaluate</ref>(self,<sp/>inputs,<sp/>targets):</highlight></codeline>
<codeline lineno="400"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="401"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>inputs<sp/></highlight><highlight class="keywordflow">is</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">or</highlight><highlight class="normal"><sp/>targets<sp/></highlight><highlight class="keywordflow">is</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="402"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="403"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="404"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#if<sp/>numframes_per_batch<sp/>is<sp/>not<sp/>set<sp/>just<sp/>process<sp/>the<sp/>entire<sp/>batch</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="405"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a206fa47fd1d8fbf5d723811b1bbc0bee" kindref="member">numframes_per_batch</ref>==-1<sp/></highlight><highlight class="keywordflow">or</highlight><highlight class="normal"><sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a206fa47fd1d8fbf5d723811b1bbc0bee" kindref="member">numframes_per_batch</ref>&gt;inputs.shape[0]:</highlight></codeline>
<codeline lineno="406"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>numframes_per_batch<sp/>=<sp/>inputs.shape[0]</highlight></codeline>
<codeline lineno="407"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="408"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>numframes_per_batch<sp/>=<sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a206fa47fd1d8fbf5d723811b1bbc0bee" kindref="member">numframes_per_batch</ref></highlight></codeline>
<codeline lineno="409"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="410"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#feed<sp/>in<sp/>the<sp/>batches<sp/>one<sp/>by<sp/>one<sp/>and<sp/>accumulate<sp/>the<sp/>loss</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="411"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>k<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>range(int(inputs.shape[0]/self.<ref refid="classnnetgraph_1_1NnetTrainer_1a206fa47fd1d8fbf5d723811b1bbc0bee" kindref="member">numframes_per_batch</ref>)<sp/>+<sp/>int(inputs.shape[0]%self.<ref refid="classnnetgraph_1_1NnetTrainer_1a206fa47fd1d8fbf5d723811b1bbc0bee" kindref="member">numframes_per_batch</ref><sp/>&gt;<sp/>0)):</highlight></codeline>
<codeline lineno="412"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>batchInputs<sp/>=<sp/>inputs[k*self.<ref refid="classnnetgraph_1_1NnetTrainer_1a206fa47fd1d8fbf5d723811b1bbc0bee" kindref="member">numframes_per_batch</ref>:min((k+1)*self.<ref refid="classnnetgraph_1_1NnetTrainer_1a206fa47fd1d8fbf5d723811b1bbc0bee" kindref="member">numframes_per_batch</ref>,<sp/>inputs.shape[0]),<sp/>:]</highlight></codeline>
<codeline lineno="413"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>batchTargets<sp/>=<sp/>targets[k*self.<ref refid="classnnetgraph_1_1NnetTrainer_1a206fa47fd1d8fbf5d723811b1bbc0bee" kindref="member">numframes_per_batch</ref>:min((k+1)*self.<ref refid="classnnetgraph_1_1NnetTrainer_1a206fa47fd1d8fbf5d723811b1bbc0bee" kindref="member">numframes_per_batch</ref>,<sp/>inputs.shape[0]),<sp/>:]</highlight></codeline>
<codeline lineno="414"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.updateValidLoss.run(feed_dict<sp/>=<sp/>{self.nnetGraph.inputs:batchInputs,<sp/>self.<ref refid="classnnetgraph_1_1NnetTrainer_1a5b7207158a2a66c947912adeb23a8559" kindref="member">targets</ref>:batchTargets})</highlight></codeline>
<codeline lineno="415"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="416"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#get<sp/>the<sp/>loss</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="417"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>loss<sp/>=<sp/>self.average_loss.eval(feed_dict<sp/>=<sp/>{self.<ref refid="classnnetgraph_1_1NnetTrainer_1abb8e4f89811de6b61fbec9a428f3bb21" kindref="member">num_frames</ref>:inputs.shape[0]})</highlight></codeline>
<codeline lineno="418"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="419"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#reinitialize<sp/>the<sp/>loss</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="420"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.initloss.run()</highlight></codeline>
<codeline lineno="421"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="422"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>loss</highlight></codeline>
<codeline lineno="423"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="424"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="425"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##halve<sp/>the<sp/>learning<sp/>rate</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="426"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetTrainer_1a9b98444e79d8d5c58f619d9d9d651ddf" kindref="member">halve_learning_rate</ref>(self):</highlight></codeline>
<codeline lineno="427"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.halveLearningRateOp.run()</highlight></codeline>
<codeline lineno="428"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="429"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##Save<sp/>the<sp/>model</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="430"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="431"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>filename<sp/>path<sp/>to<sp/>the<sp/>model<sp/>file</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="432"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetTrainer_1ac2f3d3cc6277614fea8b187994deb852" kindref="member">saveModel</ref>(self,<sp/>filename):</highlight></codeline>
<codeline lineno="433"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.nnetGraph.saver.save(tf.get_default_session(),<sp/>filename)</highlight></codeline>
<codeline lineno="434"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="435"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##Load<sp/>the<sp/>model</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="436"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="437"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>filename<sp/>path<sp/>where<sp/>the<sp/>model<sp/>will<sp/>be<sp/>saved</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="438"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetTrainer_1adf7d34bbbe5d6c719299317741b61ebe" kindref="member">restoreModel</ref>(self,<sp/>filename):</highlight></codeline>
<codeline lineno="439"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.nnetGraph.saver.restore(tf.get_default_session(),<sp/>filename)</highlight></codeline>
<codeline lineno="440"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="441"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##Save<sp/>the<sp/>training<sp/>progress<sp/>(including<sp/>the<sp/>model)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="442"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="443"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>filename<sp/>path<sp/>where<sp/>the<sp/>model<sp/>will<sp/>be<sp/>saved</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="444"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetTrainer_1a036c80b4b086ba19051ddee758ec95fe" kindref="member">saveTrainer</ref>(self,<sp/>filename):</highlight></codeline>
<codeline lineno="445"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.nnetGraph.saver.save(tf.get_default_session(),<sp/>filename)</highlight></codeline>
<codeline lineno="446"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.saver.save(tf.get_default_session(),<sp/>filename<sp/>+<sp/></highlight><highlight class="stringliteral">&apos;_trainvars&apos;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="447"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="448"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##Load<sp/>the<sp/>training<sp/>progress<sp/>(including<sp/>the<sp/>model)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="449"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="450"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>filename<sp/>path<sp/>where<sp/>the<sp/>model<sp/>will<sp/>be<sp/>saved</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="451"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1NnetTrainer_1a4c78092dedea69777c802d951b463a69" kindref="member">restoreTrainer</ref>(self,<sp/>filename):</highlight></codeline>
<codeline lineno="452"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.nnetGraph.saver.restore(tf.get_default_session(),<sp/>filename)</highlight></codeline>
<codeline lineno="453"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.saver.restore(tf.get_default_session(),<sp/>filename<sp/>+<sp/></highlight><highlight class="stringliteral">&apos;_trainvars&apos;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="454"><highlight class="normal"></highlight></codeline>
<codeline lineno="455"><highlight class="normal"></highlight><highlight class="comment">##A<sp/>class<sp/>for<sp/>a<sp/>tensor<sp/>that<sp/>is<sp/>callable<sp/><sp/><sp/><sp/><sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="456" refid="classnnetgraph_1_1CallableTensor" refkind="compound"><highlight class="normal"></highlight><highlight class="keyword">class<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1CallableTensor" kindref="compound">CallableTensor</ref>:</highlight></codeline>
<codeline lineno="457"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##CallableTensor<sp/>constructor</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="458"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="459"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@param<sp/>tensor<sp/>a<sp/>tensor</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="460"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1CallableTensor_1a4766f69abe06153da5b53afe4ce55a4c" kindref="member">__init__</ref>(self,<sp/>tensor):</highlight></codeline>
<codeline lineno="461"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classnnetgraph_1_1CallableTensor_1a9de629bb1df1ce5e3327e5cf90fdc9e0" kindref="member">tensor</ref><sp/>=<sp/>tensor</highlight></codeline>
<codeline lineno="462"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">##get<sp/>the<sp/>tensor</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="463"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="464"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#@return<sp/>the<sp/>tensor</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="465"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classnnetgraph_1_1CallableTensor_1a87f8d02412caffca0c67b07697425a6d" kindref="member">__call__</ref>(self):</highlight></codeline>
<codeline lineno="466"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>self.<ref refid="classnnetgraph_1_1CallableTensor_1a9de629bb1df1ce5e3327e5cf90fdc9e0" kindref="member">tensor</ref></highlight></codeline>
<codeline lineno="467"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="468"><highlight class="normal"></highlight></codeline>
    </programlisting>
    <location file="/users/spraak/vrenkens/code/tfkaldi/neuralNetworks/nnetgraph.py"/>
  </compounddef>
</doxygen>
